{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import imageio as img\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for the directory to the data\n",
    "todata = \"/home/abdullah/Desktop/Abdullah/LUMS/Senior/Sproj/ImgPreProcessing/Channel/\"\n",
    "moredata = \"/home/abdullah/Desktop/Abdullah/LUMS/Senior/Sproj/ImgPreProcessing/AmplifiedDataset\"\n",
    "\n",
    "\n",
    "training_iters = 1001\n",
    "learning_rate = 0.0003 \n",
    "batch_size = 64\n",
    "\n",
    "# data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# total classes (0-9 digits)\n",
    "n_classes = 26\n",
    "\n",
    "norm = 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data labales matrix\n",
      "['A' 'A' 'A' ... 'Z' 'Z' 'Z'] <U1 (3844,)\n",
      "\n",
      "Data matrix\n",
      "float32 (3844, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# saving current directory\n",
    "cur = os.getcwd()\n",
    "\n",
    "# changing directoy to data set\n",
    "os.chdir(todata)\n",
    "# getting all the folder names\n",
    "nmes = os.listdir(\".\")\n",
    "nmes.sort()\n",
    "\n",
    "# reading all the data into labels and data numpy arrays\n",
    "labels = []\n",
    "data = []\n",
    "for letr in nmes:\n",
    "    for file in os.listdir(todata+letr):\n",
    "        labels.append(letr)\n",
    "        f = img.imread(todata + letr + \"/\"+ file)\n",
    "        data.append(f)\n",
    "#         print(f.shape)\n",
    "#         plt.imshow(f)\n",
    "#         plt.show()\n",
    "#         break\n",
    "#     break\n",
    "        # change back directory\n",
    "os.chdir(cur)\n",
    "\n",
    "print(\"\\nData labales matrix\")\n",
    "labels = np.array(labels)\n",
    "print(labels, labels.dtype, labels.shape)\n",
    "\n",
    "# diving by 255 to get clamp values between zero and one\n",
    "print(\"\\nData matrix\")\n",
    "data = np.array(data, np.float32)/norm\n",
    "print(data.dtype, data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3844, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# converting labels into onehot encodings\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "# print(integer_encoded)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that splits up the data\n",
    "\n",
    "def train_val_split(data, labels, keep):\n",
    "  \n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    #split the data\n",
    "    number_of_validation_points = data.shape[0]\n",
    "\n",
    "    split = int(number_of_validation_points*keep)\n",
    "\n",
    "    # getting curent state so shuffle is the same for both arrays\n",
    "    curState = np.random.get_state()\n",
    "    np.random.shuffle(data)\n",
    "    # setting the state\n",
    "    np.random.set_state(curState)\n",
    "    np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "\n",
    "    #images are unflattened\n",
    "    temp_val = data[split:]\n",
    "    val_label = labels[split:]\n",
    "    temp_train = data[:split]\n",
    "    train_label = labels[:split]\n",
    "\n",
    "    val = temp_val\n",
    "    train = temp_train\n",
    "    \n",
    "    train = np.array(train)\n",
    "    val = np.array(val)\n",
    "\n",
    "    print(\"The splits are: \")\n",
    "    print(train.shape)   \n",
    "    print(train_label.shape)\n",
    "    print(val.shape) \n",
    "    print(val_label.shape)\n",
    "\n",
    "    return train, train_label, val, val_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The splits are: \n",
      "(3075, 28, 28)\n",
      "(3075, 26)\n",
      "(769, 28, 28)\n",
      "(769, 26)\n"
     ]
    }
   ],
   "source": [
    "# splitting up the data\n",
    "tr, tr_l, vl, vl_l = train_val_split(data, onehot_encoded, 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3075, 28, 28, 1), (769, 28, 28, 1), (3075, 26), (769, 26))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = tr.reshape(-1, n_input, n_input, 1)\n",
    "test_X = vl.reshape(-1,n_input,n_input, 1)\n",
    "\n",
    "\n",
    "\n",
    "train_y = tr_l\n",
    "test_y = vl_l\n",
    "\n",
    "train_X.shape, test_X.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow variables will be assigned inside the functions\n",
    "\n",
    "# simple convolution layer\n",
    "def conv_layer(inp, ch_in, ch_out, kernel, name=\"conv\", strides=1, k=2):\n",
    "    # giving the same naming structure for graph in tensorboard\n",
    "    with tf.name_scope(name):\n",
    "        # the first two are kernel dimen then its the input depth and \n",
    "        # then the number of filters you want ie output depth\n",
    "        w = tf.Variable(tf.truncated_normal([kernel, kernel, ch_in, ch_out], stddev=0.3), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.01, shape=[ch_out]), name=\"B\")\n",
    "\n",
    "        # applying the kernel\n",
    "        conv = tf.nn.conv2d(inp, w, strides=[1, strides, strides,1], padding=\"SAME\")\n",
    "\n",
    "        # activation\n",
    "        conv = tf.nn.bias_add(conv, b)\n",
    "        act = tf.nn.tanh(conv)\n",
    "        # summaries\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "def fc_layer(inp, ch_in, ch_out, name=\"fullyConnected\"):\n",
    "    # giving the same naming structure for graph in tensorboard\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([ch_in, ch_out], stddev=0.3), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.01, shape=[ch_out]), name=\"B\")\n",
    "\n",
    "        # linear operation and activation\n",
    "        fc = tf.matmul(inp, w)\n",
    "        fc = tf.nn.bias_add(fc, b)\n",
    "        act = tf.nn.tanh(fc)\n",
    "        act = tf.nn.dropout(act, 0.9)\n",
    "        # summaries\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the whole compuational graph/network\n",
    "def conv_net(x):  \n",
    "\n",
    "    # pooling is done inside the conv layers\n",
    "    # here we call the convolution layer we had defined above and pass the input image x\n",
    "    # since image is grascale input channel = 1 and output we specified to 32 kernels\n",
    "    conv1 = conv_layer(x, 1, 32, 3, \"conv1\")\n",
    "\n",
    "    # here we call the convolution layer we had defined above.\n",
    "    conv2 = conv_layer(conv1, 32, 64, 3, \"conv2\")\n",
    "\n",
    "\n",
    "    \n",
    "    conv3 = conv_layer(conv2, 64, 128, 4, \"conv3\")\n",
    "\n",
    "    \n",
    "\n",
    "    # flatten the ouput of pool for fully connected\n",
    "    # Reshape output to fit fully connected layer input\n",
    "    flat = tf.reshape(conv3, [-1, math.ceil(n_classes/8)*math.ceil(n_classes/8)*128])\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = fc_layer(flat, math.ceil(n_classes/8)*math.ceil(n_classes/8)*128, 1024, \"fc1\")\n",
    "\n",
    "    fc2 = fc_layer(fc1, 1024, 512, \"fc2\")\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = fc_layer(fc2, 512, n_classes,\"out\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10, Loss= 3.138590, Training Accuracy= 0.09375\n",
      "Iter 20, Loss= 2.809003, Training Accuracy= 0.18750\n",
      "Testing Accuracy: 0.18986\n",
      "Iter 30, Loss= 2.691296, Training Accuracy= 0.12500\n",
      "Iter 40, Loss= 2.428527, Training Accuracy= 0.32812\n",
      "Iter 50, Loss= 2.318340, Training Accuracy= 0.35938\n",
      "Testing Accuracy: 0.25488\n",
      "Iter 60, Loss= 2.207719, Training Accuracy= 0.48438\n",
      "Iter 70, Loss= 2.270008, Training Accuracy= 0.42188\n",
      "Testing Accuracy: 0.35371\n",
      "Iter 80, Loss= 2.148762, Training Accuracy= 0.46875\n",
      "Iter 90, Loss= 2.155006, Training Accuracy= 0.56250\n",
      "Iter 100, Loss= 2.080844, Training Accuracy= 0.56250\n",
      "Testing Accuracy: 0.39662\n",
      "Iter 110, Loss= 1.983275, Training Accuracy= 0.56250\n",
      "Iter 120, Loss= 2.079508, Training Accuracy= 0.59375\n",
      "Testing Accuracy: 0.45774\n",
      "Iter 130, Loss= 1.908074, Training Accuracy= 0.64062\n",
      "Iter 140, Loss= 2.002387, Training Accuracy= 0.59375\n",
      "Iter 150, Loss= 1.817871, Training Accuracy= 0.67188\n",
      "Testing Accuracy: 0.49155\n",
      "Iter 160, Loss= 1.792052, Training Accuracy= 0.65625\n",
      "Iter 170, Loss= 1.790734, Training Accuracy= 0.70312\n",
      "Testing Accuracy: 0.54096\n",
      "Iter 180, Loss= 1.838440, Training Accuracy= 0.73438\n",
      "Iter 190, Loss= 1.836979, Training Accuracy= 0.71875\n",
      "Iter 200, Loss= 1.693313, Training Accuracy= 0.78125\n",
      "Testing Accuracy: 0.56307\n",
      "Iter 210, Loss= 1.691537, Training Accuracy= 0.71875\n",
      "Iter 220, Loss= 1.811839, Training Accuracy= 0.73438\n",
      "Testing Accuracy: 0.60078\n",
      "Iter 230, Loss= 1.764163, Training Accuracy= 0.75000\n",
      "Iter 240, Loss= 1.670434, Training Accuracy= 0.82812\n",
      "Iter 250, Loss= 1.729882, Training Accuracy= 0.76562\n",
      "Testing Accuracy: 0.62679\n",
      "Iter 260, Loss= 1.655137, Training Accuracy= 0.81250\n",
      "Iter 270, Loss= 1.799560, Training Accuracy= 0.70312\n",
      "Testing Accuracy: 0.62679\n",
      "Iter 280, Loss= 1.628639, Training Accuracy= 0.84375\n",
      "Iter 290, Loss= 1.756881, Training Accuracy= 0.79688\n",
      "Iter 300, Loss= 1.652508, Training Accuracy= 0.84375\n",
      "Testing Accuracy: 0.62679\n",
      "Iter 310, Loss= 1.727518, Training Accuracy= 0.82812\n",
      "Iter 320, Loss= 1.718350, Training Accuracy= 0.84375\n",
      "Testing Accuracy: 0.65670\n",
      "Iter 330, Loss= 1.639369, Training Accuracy= 0.85938\n",
      "Iter 340, Loss= 1.681246, Training Accuracy= 0.75000\n",
      "Iter 350, Loss= 1.549329, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.64499\n",
      "Iter 360, Loss= 1.609858, Training Accuracy= 0.87500\n",
      "Iter 370, Loss= 1.635401, Training Accuracy= 0.82812\n",
      "Testing Accuracy: 0.66450\n",
      "Iter 380, Loss= 1.657725, Training Accuracy= 0.79688\n",
      "Iter 390, Loss= 1.674566, Training Accuracy= 0.89062\n",
      "Iter 400, Loss= 1.606993, Training Accuracy= 0.84375\n",
      "Testing Accuracy: 0.71521\n",
      "Iter 410, Loss= 1.588384, Training Accuracy= 0.92188\n",
      "Iter 420, Loss= 1.612339, Training Accuracy= 0.87500\n",
      "Testing Accuracy: 0.70221\n",
      "Iter 430, Loss= 1.585602, Training Accuracy= 0.89062\n",
      "Iter 440, Loss= 1.565432, Training Accuracy= 0.92188\n",
      "Iter 450, Loss= 1.643343, Training Accuracy= 0.85938\n",
      "Testing Accuracy: 0.69571\n",
      "Iter 460, Loss= 1.571897, Training Accuracy= 0.90625\n",
      "Iter 470, Loss= 1.672511, Training Accuracy= 0.85938\n",
      "Testing Accuracy: 0.72302\n",
      "Iter 480, Loss= 1.615402, Training Accuracy= 0.89062\n",
      "Iter 490, Loss= 1.603985, Training Accuracy= 0.92188\n",
      "Iter 500, Loss= 1.588491, Training Accuracy= 0.89062\n",
      "Testing Accuracy: 0.71131\n",
      "Iter 510, Loss= 1.572671, Training Accuracy= 0.93750\n",
      "Iter 520, Loss= 1.650004, Training Accuracy= 0.82812\n",
      "Testing Accuracy: 0.71261\n",
      "Iter 530, Loss= 1.573262, Training Accuracy= 0.89062\n",
      "Iter 540, Loss= 1.579679, Training Accuracy= 0.89062\n",
      "Iter 550, Loss= 1.674266, Training Accuracy= 0.84375\n",
      "Testing Accuracy: 0.72952\n",
      "Iter 560, Loss= 1.681432, Training Accuracy= 0.82812\n",
      "Iter 570, Loss= 1.594521, Training Accuracy= 0.90625\n",
      "Testing Accuracy: 0.75683\n",
      "Iter 580, Loss= 1.551133, Training Accuracy= 0.93750\n",
      "Iter 590, Loss= 1.538799, Training Accuracy= 0.96875\n",
      "Iter 600, Loss= 1.506310, Training Accuracy= 0.96875\n",
      "Testing Accuracy: 0.74772\n",
      "Iter 610, Loss= 1.538836, Training Accuracy= 0.96875\n",
      "Iter 620, Loss= 1.609743, Training Accuracy= 0.85938\n",
      "Testing Accuracy: 0.75813\n",
      "Iter 630, Loss= 1.551330, Training Accuracy= 0.95312\n",
      "Iter 640, Loss= 1.563532, Training Accuracy= 0.92188\n",
      "Iter 650, Loss= 1.563420, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.74642\n",
      "Iter 660, Loss= 1.567860, Training Accuracy= 0.89062\n",
      "Iter 670, Loss= 1.585901, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.74512\n",
      "Iter 680, Loss= 1.574563, Training Accuracy= 0.92188\n",
      "Iter 690, Loss= 1.547407, Training Accuracy= 0.95312\n",
      "Iter 700, Loss= 1.591648, Training Accuracy= 0.90625\n",
      "Testing Accuracy: 0.73862\n",
      "Iter 710, Loss= 1.650515, Training Accuracy= 0.84375\n",
      "Iter 720, Loss= 1.564510, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.75293\n",
      "Iter 730, Loss= 1.621455, Training Accuracy= 0.87500\n",
      "Iter 740, Loss= 1.561797, Training Accuracy= 0.93750\n",
      "Iter 750, Loss= 1.619609, Training Accuracy= 0.87500\n",
      "Testing Accuracy: 0.80234\n",
      "Iter 760, Loss= 1.557825, Training Accuracy= 0.89062\n",
      "Iter 770, Loss= 1.639383, Training Accuracy= 0.85938\n",
      "Testing Accuracy: 0.79584\n",
      "Iter 780, Loss= 1.604213, Training Accuracy= 0.93750\n",
      "Iter 790, Loss= 1.569268, Training Accuracy= 0.90625\n",
      "Iter 800, Loss= 1.549287, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.75293\n",
      "Iter 810, Loss= 1.539146, Training Accuracy= 0.93750\n",
      "Iter 820, Loss= 1.578652, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.77113\n",
      "Iter 830, Loss= 1.516559, Training Accuracy= 0.96875\n",
      "Iter 840, Loss= 1.579135, Training Accuracy= 0.90625\n",
      "Iter 850, Loss= 1.560884, Training Accuracy= 0.96875\n",
      "Testing Accuracy: 0.79324\n",
      "Iter 860, Loss= 1.565667, Training Accuracy= 0.90625\n",
      "Iter 870, Loss= 1.542372, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.77633\n",
      "Iter 880, Loss= 1.651349, Training Accuracy= 0.89062\n",
      "Iter 890, Loss= 1.590143, Training Accuracy= 0.89062\n",
      "Iter 900, Loss= 1.573374, Training Accuracy= 0.92188\n",
      "Testing Accuracy: 0.79844\n",
      "Iter 910, Loss= 1.536444, Training Accuracy= 0.93750\n",
      "Iter 920, Loss= 1.534479, Training Accuracy= 0.95312\n",
      "Testing Accuracy: 0.77373\n",
      "Iter 930, Loss= 1.614353, Training Accuracy= 0.89062\n",
      "Iter 940, Loss= 1.531655, Training Accuracy= 0.95312\n",
      "Iter 950, Loss= 1.553985, Training Accuracy= 0.96875\n",
      "Testing Accuracy: 0.76203\n",
      "Iter 960, Loss= 1.547913, Training Accuracy= 0.92188\n",
      "Iter 970, Loss= 1.555566, Training Accuracy= 0.96875\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()# telling the session to initialize the variables\n",
    "\n",
    "\n",
    "# input dimen and output dimen\n",
    "x = tf.placeholder(\"float\", [None, n_input,n_input, 1], name=\"x\")\n",
    "tf.summary.image('input', x, 10)\n",
    "\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name = \"labels\")\n",
    "\n",
    "# storing the graph in the variable pred\n",
    "pred = conv_net(x)\n",
    "\n",
    "# cost fucntion for the graph\n",
    "with tf.name_scope(\"entropy\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    tf.summary.scalar(\"entropy\", cost)\n",
    "\n",
    "# optiizr for the network\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    #Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled \n",
    "    #image. and both will be a column vector.\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    #calculate accuracy across all the given images and average them out. \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "# storing the values in lists\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter('./Output')\n",
    "summary_writer.add_graph(sess.graph)\n",
    "\n",
    "for i in range(1,training_iters):\n",
    "    for batch in range(len(train_X)//batch_size):\n",
    "        batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "        batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "        # Run optimization op (backprop).\n",
    "        # Calculate batch loss and accuracy\n",
    "        opt = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (i % 5 == 0)&(batch == 0):\n",
    "            s = sess.run(summ, feed_dict={x: batch_x, y: batch_y})\n",
    "            summary_writer.add_summary(s, i)\n",
    "    if i % 10 == 0:\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "#         print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for all test images\n",
    "    test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "    train_loss.append(loss)\n",
    "    test_loss.append(valid_loss)\n",
    "    train_accuracy.append(acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    if i % 25 == 0:\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
