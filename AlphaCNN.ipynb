{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import imageio as img\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for the directory to the data\n",
    "todata = \"/home/abdullah/Desktop/Abdullah/LUMS/Senior/Sproj/ImgPreProcessing/Channel/\"\n",
    "moredata = \"/home/abdullah/Desktop/Abdullah/LUMS/Senior/Sproj/ImgPreProcessing/AmplifiedDataset\"\n",
    "\n",
    "\n",
    "training_iters = 50\n",
    "learning_rate = 0.001 \n",
    "batch_size = 128\n",
    "\n",
    "# data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# total classes (0-9 digits)\n",
    "n_classes = 26\n",
    "\n",
    "norm = 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data labales matrix\n",
      "['A' 'A' 'A' ... 'Z' 'Z' 'Z'] <U1 (3844,)\n",
      "\n",
      "Data matrix\n",
      "float32 (3844, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# saving current directory\n",
    "cur = os.getcwd()\n",
    "\n",
    "# changing directoy to data set\n",
    "os.chdir(todata)\n",
    "# getting all the folder names\n",
    "nmes = os.listdir(\".\")\n",
    "nmes.sort()\n",
    "\n",
    "# reading all the data into labels and data numpy arrays\n",
    "labels = []\n",
    "data = []\n",
    "for letr in nmes:\n",
    "    for file in os.listdir(todata+letr):\n",
    "        labels.append(letr)\n",
    "        f = img.imread(todata + letr + \"/\"+ file)\n",
    "        data.append(f)\n",
    "#         print(f.shape)\n",
    "#         plt.imshow(f)\n",
    "#         plt.show()\n",
    "#         break\n",
    "#     break\n",
    "        # change back directory\n",
    "os.chdir(cur)\n",
    "\n",
    "print(\"\\nData labales matrix\")\n",
    "labels = np.array(labels)\n",
    "print(labels, labels.dtype, labels.shape)\n",
    "\n",
    "# diving by 255 to get clamp values between zero and one\n",
    "print(\"\\nData matrix\")\n",
    "data = np.array(data, np.float32)/norm\n",
    "print(data.dtype, data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3844, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# converting labels into onehot encodings\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "# print(integer_encoded)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that splits up the data\n",
    "\n",
    "def train_val_split(data, labels, keep):\n",
    "  \n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    #split the data\n",
    "    number_of_validation_points = data.shape[0]\n",
    "\n",
    "    split = int(number_of_validation_points*keep)\n",
    "\n",
    "    # getting curent state so shuffle is the same for both arrays\n",
    "    curState = np.random.get_state()\n",
    "    np.random.shuffle(data)\n",
    "    # setting the state\n",
    "    np.random.set_state(curState)\n",
    "    np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "\n",
    "    #images are unflattened\n",
    "    temp_val = data[split:]\n",
    "    val_label = labels[split:]\n",
    "    temp_train = data[:split]\n",
    "    train_label = labels[:split]\n",
    "\n",
    "    val = temp_val\n",
    "    train = temp_train\n",
    "    \n",
    "    train = np.array(train)\n",
    "    val = np.array(val)\n",
    "\n",
    "    print(\"The splits are: \")\n",
    "    print(train.shape)   \n",
    "    print(train_label.shape)\n",
    "    print(val.shape) \n",
    "    print(val_label.shape)\n",
    "\n",
    "    return train, train_label, val, val_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The splits are: \n",
      "(3075, 28, 28)\n",
      "(3075, 26)\n",
      "(769, 28, 28)\n",
      "(769, 26)\n"
     ]
    }
   ],
   "source": [
    "# splitting up the data\n",
    "tr, tr_l, vl, vl_l = train_val_split(data, onehot_encoded, 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3075, 28, 28, 1), (769, 28, 28, 1), (3075, 26), (769, 26))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = tr.reshape(-1, n_input, n_input, 1)\n",
    "test_X = vl.reshape(-1,n_input,n_input, 1)\n",
    "\n",
    "\n",
    "\n",
    "train_y = tr_l\n",
    "test_y = vl_l\n",
    "\n",
    "train_X.shape, test_X.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow variables will be assigned inside the functions\n",
    "\n",
    "# simple convolution layer\n",
    "def conv_layer(inp, ch_in, ch_out, name=\"conv\", strides=1, k=2):\n",
    "    # giving the same naming structure for graph in tensorboard\n",
    "    with tf.name_scope(name):\n",
    "        # the first two are kernel dimen then its the input depth and \n",
    "        # then the number of filters you want ie output depth\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, ch_in, ch_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[ch_out]), name=\"B\")\n",
    "\n",
    "        # applying the kernel\n",
    "        conv = tf.nn.conv2d(inp, w, strides=[1, strides, strides,1], padding=\"SAME\")\n",
    "\n",
    "        # activation\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        # summaries\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "def fc_layer(inp, ch_in, ch_out, name=\"fulluConnected\"):\n",
    "    # giving the same naming structure for graph in tensorboard\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([ch_in, ch_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[ch_out]), name=\"B\")\n",
    "\n",
    "        # linear operation and activation\n",
    "        act = tf.nn.relu(tf.matmul(inp, w) + b)\n",
    "        # summaries\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the whole compuational graph/network\n",
    "def conv_net(x):  \n",
    "\n",
    "    # pooling is done inside the conv layers\n",
    "    # here we call the convolution layer we had defined above and pass the input image x\n",
    "    # since image is grascale input channel = 1 and output we specified to 32 kernels\n",
    "    conv1 = conv_layer(x, 1, 32, \"conv1\")\n",
    "\n",
    "    # here we call the convolution layer we had defined above.\n",
    "    conv2 = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "\n",
    "    conv3 = conv_layer(conv2, 64, 128, \"conv3\")\n",
    "\n",
    "\n",
    "    # flatten the ouput of pool for fully connected\n",
    "    # Reshape output to fit fully connected layer input\n",
    "    flat = tf.reshape(conv3, [-1, math.ceil(n_classes/8)*math.ceil(n_classes/8)*128])\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = fc_layer(flat, math.ceil(n_classes/8)*math.ceil(n_classes/8)*128, 1024, \"fc1\")\n",
    "\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = fc_layer(fc1, 1024, n_classes,\"fc2\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abdullah/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Iter 0, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 1, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 2, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 3, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 4, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 5, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 6, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 7, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 8, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 9, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 10, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 11, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 12, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 13, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 14, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 15, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 16, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 17, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 18, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 19, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 20, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 21, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 22, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 23, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 24, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 25, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 26, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 27, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 28, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 29, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 30, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 31, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 32, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 33, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 34, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 35, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 36, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 37, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 38, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 39, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 40, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 41, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n",
      "Iter 42, Loss= 3.258096, Training Accuracy= 0.05469\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04291\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()# telling the session to initialize the variables\n",
    "\n",
    "\n",
    "# input dimen and output dimen\n",
    "x = tf.placeholder(\"float\", [None, n_input,n_input, 1], name=\"x\")\n",
    "tf.summary.image('input', x, 10)\n",
    "\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name = \"labels\")\n",
    "\n",
    "# storing the graph in the variable pred\n",
    "pred = conv_net(x)\n",
    "\n",
    "# cost fucntion for the graph\n",
    "with tf.name_scope(\"entropy\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "    tf.summary.scalar(\"entropy\", cost)\n",
    "\n",
    "# optiizr for the network\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    #Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    #calculate accuracy across all the given images and average them out. \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "# storing the values in lists\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter('./Output')\n",
    "summary_writer.add_graph(sess.graph)\n",
    "for i in range(training_iters):\n",
    "    for batch in range(len(train_X)//batch_size):\n",
    "        batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "        batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "        # Run optimization op (backprop).\n",
    "        # Calculate batch loss and accuracy\n",
    "        opt = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (i % 5 == 0)&(batch == 0):\n",
    "            s = sess.run(summ, feed_dict={x: batch_x, y: batch_y})\n",
    "            summary_writer.add_summary(s, i)\n",
    "        \n",
    "    print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for all test images\n",
    "    test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "    train_loss.append(loss)\n",
    "    test_loss.append(valid_loss)\n",
    "    train_accuracy.append(acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
